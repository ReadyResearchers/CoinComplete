{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from binance.client import Client\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ModelCheckpoint\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 60  # how long of a preceding sequence to collect for RNN\n",
    "FUTURE_PERIOD_PREDICT = 3  # future prediction length\n",
    "RATIO_TO_PREDICT = \"BTC\" # Coin being predicted\n",
    "EPOCHS = 10  # passes\n",
    "BATCH_SIZE = 64  # amount of in batch\n",
    "NAME = f\"{RATIO_TO_PREDICT}-{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\" # Change Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(current, future):\n",
    "    if float(future) > float(current):  # if the future price is higher than the current = buy\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    df = df.drop(\"future\", 1)\n",
    "    for col in df.columns:\n",
    "        if col != \"target\":\n",
    "            if df[col].dtype != \"object\":  # only apply to numerical columns\n",
    "                df[col] = df[col].pct_change()\n",
    "                df[col].replace([np.inf, -np.inf], np.nan, inplace=True)  # replace inf with NaN\n",
    "                df[col].dropna(inplace=True)  # remove NaN\n",
    "                df[col] = preprocessing.scale(df[col].values)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    sequential_data = []\n",
    "    prev_days = deque(maxlen=SEQ_LEN)\n",
    "\n",
    "    for i in df.values:\n",
    "        prev_days.append([n for n in i[:-1]])\n",
    "        if len(prev_days) == SEQ_LEN:\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])\n",
    "\n",
    "    random.shuffle(sequential_data)\n",
    "\n",
    "    buys = []\n",
    "    sells = []\n",
    "\n",
    "    for seq, target in sequential_data:\n",
    "        if target == 0:\n",
    "            sells.append([seq, target])\n",
    "        elif target == 1:\n",
    "            buys.append([seq, target])\n",
    "\n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "\n",
    "    lower = min(len(buys), len(sells))\n",
    "\n",
    "    buys = buys[:lower]\n",
    "    sells = sells[:lower]\n",
    "\n",
    "    sequential_data = buys+sells\n",
    "    random.shuffle(sequential_data)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "\n",
    "    return np.array(X), y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame() # begin empty\n",
    "\n",
    "ratios = [\"BTC\", \"ETH\"]  \n",
    "for ratio in ratios:  # begin iteration\n",
    "\n",
    "    print(ratio)\n",
    "    dataset = f'data/{ratio}_2021_1y.csv'  # get the full path to the file.\n",
    "    columns = ['OpenTime', \n",
    "            f'{ratio}-USD_Open', \n",
    "            f'{ratio}-USD_High', \n",
    "            f'{ratio}-USD_Low', \n",
    "            f'{ratio}-USD_Close', \n",
    "            f'{ratio}-USD_volume']\n",
    "    df = pd.read_csv(dataset)  # read in specific file\n",
    "    df = df[columns]\n",
    "\n",
    "    print(df)\n",
    "    \n",
    "    dts = []\n",
    "    df = df[df['OpenTime'].notnull()]\n",
    "    for i in range(len(df)):\n",
    "        dts.append(datetime.strptime(df['OpenTime'].iloc[i].split('.')[0], '%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    df['OpenTime'] = dts\n",
    "\n",
    "    df.set_index(\"OpenTime\", inplace=True)  # set time as index so we can join them on this shared time\n",
    "    df = df[[f'{ratio}-USD_Close', f\"{ratio}-USD_volume\"]]  # ignore the other columns besides price and volume\n",
    "\n",
    "    if len(main_df)==0:  # if the dataframe is empty\n",
    "        main_df = df  # then it's just the current df\n",
    "    else:  # otherwise, join this data to the main one\n",
    "        main_df = main_df.join(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.fillna(method=\"ffill\", inplace=True)  # if there are gaps in data, use previously known values\n",
    "main_df.dropna(inplace=True)\n",
    "#print(main_df.head(50))  # print DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df[f'{ratio}-USD_Close'] = pd.to_numeric(main_df[f'{ratio}-USD_Close'], errors='coerce')\n",
    "main_df[f'{ratio}-USD_volume'] = pd.to_numeric(main_df[f'{ratio}-USD_volume'], errors='coerce')\n",
    "main_df['future'] = main_df[f'{RATIO_TO_PREDICT}-USD_Close'].shift(-FUTURE_PERIOD_PREDICT)\n",
    "#print(main_df['future'].to_string())\n",
    "main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}-USD_Close'], main_df['future']))\n",
    "print(main_df.dtypes)\n",
    "print(main_df['target'].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = sorted(main_df.index.values)\n",
    "last_5pct = sorted(main_df.index.values)[-int(0.05*len(times))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_main_df = main_df[(main_df.index >= last_5pct)]\n",
    "main_df = main_df[(main_df.index < last_5pct)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main_df)\n",
    "train_x, train_y = preprocess_df(main_df)\n",
    "val_x, val_y = preprocess_df(val_main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train data: {len(train_x)} validation: {len(val_x)}\")\n",
    "print(f\"Dont buys: {train_y.count(0)}, buys: {train_y.count(1)}\")\n",
    "print(f\"VALIDATION Dont buys: {val_y.count(0)}, buys: {val_y.count(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"RNN_Final-{epoch:02d}-{val_accuracy:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "val_x = np.asarray(val_x)\n",
    "val_y = np.asarray(val_y)\n",
    "\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(val_x, val_y),\n",
    "    callbacks=[tensorboard, checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(val_x, val_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "# Save model\n",
    "model.save(\"models/{}\".format(NAME))\n",
    "%tensorboard --logdir logs/fit # LAUNCH VALIDATION METRICS HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "820ef01b352440233b0ae969ad3168ac01de210b874f98f232dff88435c68062"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
